{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wykład 10: Uczenie sieci neuronowych z Keras'em\n",
    "\n",
    "### Cel: \n",
    "- Nauka tworzenia i uczenia sieci neuronowych z `tensorflow` i Keras'em\n",
    "\n",
    "### Zbiór danych:\n",
    "- Do testów wykorzystamy zbiór ręcznie pisanych cyfr\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 42\n",
    "plt.imshow(digits.images[i], interpolation='nearest')\n",
    "plt.title(\"label: %d\" % digits.target[i]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podział danych na treningowe i testowe\n",
    "\n",
    "Tak jak w poprzednich zadaniach z regresji zrobimy podział na dane treningowe wykorzystywane do nauki sieci\n",
    "oraz testowe i na tak przygotowanych danych będziemy sprawdzać nasz model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = np.asarray(digits.data, dtype='float32')\n",
    "target = np.asarray(digits.target, dtype='int32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, test_size=0.20, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 142\n",
    "plt.imshow(X_train[i].reshape(8, 8), interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstępne przygotowanie danych wejściowych (preprocessing)\n",
    "\n",
    "Chcemy aby dane wejściowe (nasze cyfry) miały w przybliżeniu takie same parametry i znormalizowane kolory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# wykorzystamy funkcje StandardScaler\n",
    "help(preprocessing.StandardScaler)\n",
    "# lub\n",
    "preprocessing.StandardScaler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# print(scaler.mean_)\n",
    "# print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zobaczmy jak teraz wyglądają nasze dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 142\n",
    "plt.imshow(X_train[i].reshape(8, 8), interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obiekt `scaler` jest operacją odwracalną, która umożliwia nam odtworzenie oryginalnego obrazu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scaler.inverse_transform(X_train[i]).reshape(8, 8), interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstępne przygotowanie danych docelowych (naszych etykiet)\n",
    "\n",
    "Aby odpowiednio nauczyć naszą sieć neuronową musimy przetworzyć etykiety do odpowiedniego formatu.\n",
    "Zobaczmy najpierw jak wygląda nasz wektor `y_train`. Jak widać są to po prostu liczby całkowite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konwersja danych do formatu wykorzystywanego przez naszą sieć neuronową. Skorzystamy z funkcji\n",
    "Keras'a `to_categorial`. Na przykład cyfrę `9` zamieniamy na wektor `[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]`. Tak będziemy kategoryzować nasze ręcznie pisane cyfry, czyli warstwa wyjściowa będzie miała 10 neuronów (jeden dla każdej cyfry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_train[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zaprogramujemy teraz nasza sieć neuronową z wykorzystaniem Keras'a\n",
    "\n",
    "Naszym celem jest:\n",
    "\n",
    "- Budowanie i trening sieci `feedforward` z `Kerasem`\n",
    "    - https://www.tensorflow.org/guide/keras/overview\n",
    "- Eksperymentowanie z różnymi algorytmami uczenia (optimizers), funkcjami aktywacji, wielkościami warstw i inicjalizacjami wag\n",
    "\n",
    "### Model sieci neuronowej z wykorzystaniem Keras'a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystamy wysoko-poziomowe API Kerasa\n",
    "\n",
    "- na początku definiujemy nasz model jako kolejne warstwy sieci (o odpowiednich wymiarach)\n",
    "- wybieramy odpowiednią funkcję kosztu (loss) i metodę uczenia (optimizer) SGD (stochastic gradient descent)\n",
    "- następnie przekazujemy naszemu modelowi dane trenujące i ustalamy liczbę kroków uczenia (epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "input_dim = X_train.shape[1]  # warstwa wejściowa\n",
    "hidden_dim = 100              # warstwa ukryta\n",
    "output_dim = 10               # warstwa wyjściowa - 10 neuronów (każda cyfra)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_dim, input_dim=input_dim, activation=\"tanh\"))\n",
    "# przy klasyfikacji bardzo często w warstwie wyjściowej wybieramy funkcje aktywacji 'softmax'\n",
    "model.add(Dense(output_dim, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(lr=0.1),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_split=0.2, epochs=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wizualizacja procesu uczenia (zbieżność)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystajmy `pandas` do łatwiejszego przetwarzania danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df[\"epoch\"] = history.epoch\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(12, 6))\n",
    "history_df.plot(x=\"epoch\", y=[\"loss\", \"val_loss\"], ax=ax0)\n",
    "history_df.plot(x=\"epoch\", y=[\"accuracy\", \"val_accuracy\"], ax=ax1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitorowanie procesu uczenia z wykorzystaniem `Tensorboard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf tensorboard_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_dim, input_dim=input_dim, activation=\"tanh\"))\n",
    "model.add(Dense(output_dim, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(lr=0.1),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "timestamp =  datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = \"tensorboard_logs/\" + timestamp\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x=X_train, y=Y_train, validation_split=0.2, epochs=15,\n",
    "          callbacks=[tensorboard_callback]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir tensorboard_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przetestujemy różne algorytmy uczenia (optimizers)\n",
    "\n",
    "- zmniejszymy współczynnik uczenia (learning rate) o 10 lub 100. Co można zaobserwować?\n",
    "\n",
    "- zwiększymy współczynnik uczenia (learning rate) i zobaczymy jak uczenie nie jest już zbieżne.\n",
    "\n",
    "- Skonfigurujemy SGD tak aby wykorzystać moment Nesterow o wartości np. 0.9\n",
    "  \n",
    "**Dokumentacja**: \n",
    "\n",
    "Keras API: https://www.tensorflow.org/api_docs/python/tf/keras\n",
    "\n",
    "Można też skorzystać z dokumentacji z poziomu notatnika\n",
    "\n",
    "```python\n",
    "optimizers.SGD?\n",
    "```\n",
    "\n",
    "Przypominam, że mamy też podpowiedzi przez \"shift-tab\" np.\n",
    "\n",
    "```python\n",
    "optimizers.SGD(<shift-tab>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.SGD?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza\n",
    "\n",
    "- zauważmy, że ustawiając współczynnik uczenia na małą wartość (np. lr=0.001) powoduje bardzo wolny proces uczenia, w przypadku naszych danych nie mamy zbieżności po 15 epokach.\n",
    "\n",
    "- wykorzystując moment można \"złagodzić\" mały współczynnik uczenia (przynajmniej trochę ...)\n",
    "\n",
    "- natomiast ustawiając współczynnik uczenia na dużą wartość (np. lr=10) powoduje losowe krążenie w obszarze dobrego minimum i uniemożliwia osiągnięcie funkcji celu (loss) nawet po 30 epokach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(hidden_dim, input_dim=input_dim,\n",
    "                activation=\"tanh\"))\n",
    "model.add(Dense(output_dim, activation=\"softmax\"))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "optimizer = optimizers.SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, validation_split=0.2,\n",
    "                    epochs=15, batch_size=32)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(12, 6))\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df[\"epoch\"] = history.epoch\n",
    "history_df.plot(x=\"epoch\", y=[\"loss\", \"val_loss\"], ax=ax0)\n",
    "history_df.plot(x=\"epoch\", y=[\"accuracy\", \"val_accuracy\"], ax=ax1);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inne metody uczenia\n",
    "\n",
    "- zastąpimy SGD przez algorytm uczenia Adam i uruchomimy z domyślnymi parametrami. Pamiętaj, że mamy też\n",
    "    `tab-complete` dokładnie `optimizers.<TAB>`\n",
    "    \n",
    "- dodamy jeszcze jedną warstwę i wykorzystamy ReLU dla każdej warstwy ukrytej. Czy dalej możemy wykorzystać model Adam z domyślnymi parametrami uczenia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(hidden_dim, input_dim=input_dim,\n",
    "                activation=\"relu\"))\n",
    "model.add(Dense(hidden_dim, activation=\"relu\"))\n",
    "model.add(Dense(output_dim, activation=\"softmax\"))\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_split=0.2,\n",
    "                    epochs=15, batch_size=32)\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(12, 6))\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df[\"epoch\"] = history.epoch\n",
    "history_df.plot(x=\"epoch\", y=[\"loss\", \"val_loss\"], ax=ax0)\n",
    "history_df.plot(x=\"epoch\", y=[\"accuracy\", \"val_accuracy\"], ax=ax1);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza\n",
    "\n",
    "- Adam z domyślnymi parametrami i uczeniem np. 0.001 daje w wielu przypadkach zbieżność tak samo szybką lub nawet szybszą niż SGD z dobrze dobranymi eksperymentalnie parametrami dla szczególnego problemu\n",
    "\n",
    "- Adam stosuje m.in. współczynnik uczenia lokalnie dla każdego neuronu dlatego dobieranie odpowiedniego współczynnika rzadko jest potrzebne\n",
    "\n",
    "### Adam:     https://arxiv.org/abs/1412.6980\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wynik działania sieci na zbiorze testowym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=5, nrows=3, figsize=(12, 9))\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.imshow(scaler.inverse_transform(X_test[i]).reshape(8, 8), interpolation='nearest')\n",
    "    ax.set_title(\"predicted label: %d\\n true label: %d\" % (y_predicted[i], y_test[i]))\n",
    "    \n",
    "print(\"test acc: %0.4f\" % np.mean(y_predicted == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wpływ algorytmów uczenia na początkowy wybór wag\n",
    "\n",
    "Zobaczmy teraz wpływ złego wyboru początkowego wag (initialization) na uczenie\n",
    "sieci neuronowych.\n",
    "\n",
    "Domyślnie warstwy Keras'a (Dense layers) wykorzystują strategię inicjalizacji <cite>\"Glorot Uniform\"[1][2][3]</cite> wag macierzy:\n",
    "\n",
    "- każdy współczynnik wagi pochodzi z rozkładu jednostajnego na przedziale $[-\\delta, \\delta]$, gdzie  \n",
    "  $$\\delta \\sim \\frac{1}{\\sqrt{n_{in} + n_{out}}}$$\n",
    "  oraz $n_{in}$ i $n_{out}$ to liczba wejściowych i wyjściowych połączeń.\n",
    "\n",
    "Strategia ta działa dobrze do inicjalizacji wag dla sieci neuronowych z funkcjami\n",
    "aktywacji \"tanh\" lub \"relu\" i uczona za pomocą standardowego SGD.\n",
    "\n",
    "Aby zobaczyć wpływ inicjalizacji wykorzystamy alternatywne metody inicjalizacji dla\n",
    "dwuwarstwowej sieci z \"tanh\". Dla tego konkretnego przykładu wykorzystamy do inicjalizacji\n",
    "wag rozkład normalny z dobranymi wartościami standardowego odchylenia.\n",
    "\n",
    "[1]: [Xavier Glorot, Yoshua Bengio, Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a.html)\n",
    "\n",
    "[2]: [What is the default weight initializer in keras](https://stackoverflow.com/questions/54011173/what-is-the-default-weight-initializer-in-keras)\n",
    " \n",
    "[3]: [Weight Initialization in Neural Networks: A Journey From the Basics to Kaiming](https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import initializers\n",
    "\n",
    "normal_init = initializers.TruncatedNormal(stddev=0.01)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_dim, input_dim=input_dim, activation=\"tanh\",\n",
    "                kernel_initializer=normal_init))\n",
    "model.add(Dense(hidden_dim, activation=\"tanh\",\n",
    "                kernel_initializer=normal_init))\n",
    "model.add(Dense(output_dim, activation=\"softmax\",\n",
    "                kernel_initializer=normal_init))\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(lr=0.1),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zobaczmy parametry pierwszej warstwy po inicjalizacji, ale przed uczeniem sieci. Zauważmy, że 'bias' jest ustawione na zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.layers[0].weights[0].numpy()\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = model.layers[0].weights[1].numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=15, batch_size=32)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(history.history['loss'], label=\"Truncated Normal init\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zauważmy, że po uczeniu wagi zostają zaktualizowane i \"bias\" nie mają już wartości zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testy\n",
    "\n",
    "- Wykonajmy poniższe schematy inicjalizacji i zobaczmy czy algorytm SGD nauczy lub nie naszą sieć neuronową\n",
    "\n",
    "  - małe odchylenie np. `stddev=1e-3`\n",
    "  - duże odchylenie `stddev=1` or `10`\n",
    "  - inicjalizacja wszystkich wag na $0$ (stała)\n",
    "\n",
    "- Czy metody uczenia SGD z momentem lub Adam lepiej poradzą sobie ze złą inicjalizacja wag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_scale_init = initializers.TruncatedNormal(stddev=1)\n",
    "small_scale_init = initializers.TruncatedNormal(stddev=1e-3)\n",
    "\n",
    "\n",
    "optimizer_list = [\n",
    "    ('SGD', optimizers.SGD(lr=0.1)),\n",
    "    ('Adam', optimizers.Adam()),\n",
    "    ('SGD + Nesterov momentum', optimizers.SGD(\n",
    "            lr=0.1, momentum=0.9, nesterov=True)),\n",
    "]\n",
    "\n",
    "init_list = [\n",
    "    ('glorot uniform init', 'glorot_uniform', '-'),\n",
    "    ('small init scale', small_scale_init, '-'),\n",
    "    ('large init scale', large_scale_init, '-'),\n",
    "    ('zero init', 'zero', '--'),\n",
    "]\n",
    "\n",
    "\n",
    "for optimizer_name, optimizer in optimizer_list:\n",
    "    print(\"Fitting with:\", optimizer_name)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for init_name, init, linestyle in init_list:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(hidden_dim, input_dim=input_dim, activation=\"tanh\",\n",
    "                        kernel_initializer=init))\n",
    "        model.add(Dense(hidden_dim, activation=\"tanh\",\n",
    "                        kernel_initializer=init))\n",
    "        model.add(Dense(output_dim, activation=\"softmax\",\n",
    "                        kernel_initializer=init))\n",
    "\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='categorical_crossentropy')\n",
    "\n",
    "        history = model.fit(X_train, Y_train,\n",
    "                            epochs=10, batch_size=32, verbose=0)\n",
    "        plt.plot(history.history['loss'], linestyle=linestyle,\n",
    "                 label=init_name)\n",
    "\n",
    "    plt.xlabel('# epochs')\n",
    "    plt.ylabel('Training loss')\n",
    "    plt.ylim(0, 6)\n",
    "    plt.legend(loc='best');\n",
    "    plt.title('Impact of initialization on convergence with %s'\n",
    "              % optimizer_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza\n",
    "\n",
    "- Jeśli sieć jest inicjalizowana na stała wartość zero, to aktywacja warstw ukrytych jest też ustawiana na zero,\n",
    "  niezależnie od wartości wejściowych. Gradient jest też zawsze zero. Dlatego wszystkie algorytmy bazujące\n",
    "  na spadku gradientu (SGD, Adam, ...) nie działają.\n",
    "\n",
    "- Warto zaznaczyć, że model z softmax zachowuje się inaczej ...\n",
    "\n",
    "- Dla sieci neuronowych kiedy inicjalizacja przebiegła dla małych wag. SGD ma duże problemy z powodu\n",
    "  małego gradientu. Dodanie momentu może poprawić sytuacje, ale potrzeba dużo epok do nauczenia sieci\n",
    "  \n",
    "- Inicjalizaca wag na duże wartości powoduje zepsucie warstwy wyjścia (softmax). Sieć jest \"pewna\"\n",
    "  swoich predykcji nawet jeśli są one kompletnie losowe\n",
    "\n",
    "- 'Glorot uniform' wykorzystuje lepsze dostosowanie do wymiarów macierzy i zachowuje średnią aktywacje oraz \n",
    "  gradienty co powoduje lepszy proces uczenia\n",
    "\n",
    "- Adam jest bardziej odporny na złą inicjalizację wag dzięki dobraniu współczynnika uczenia dla każdej wagi, ale\n",
    "  i tak lepiej zachowuje się dla \"dobrej\" inicjalizacji wag\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podumowanie\n",
    "\n",
    "Na razie proszę zapamiętać, że jeśli sieć nie uczy się w ogóle 'loss' pozostaje taki sam, to\n",
    "\n",
    "- upewnij się że wagi zostały dobrze dobrane\n",
    "- sprawdź sieć warstwa po warstwie patrząc na gradient może to pomóc zidentyfikować \"złą warstwę\"\n",
    "- wykorzystać Adam zamiast SGD\n",
    "\n",
    "#### https://stackoverflow.com/questions/50033312/how-to-monitor-gradient-vanish-and-explosion-in-keras-with-tensorboard\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
