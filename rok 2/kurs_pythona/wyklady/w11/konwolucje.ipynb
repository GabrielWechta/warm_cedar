{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wykład 11: Konwolucje (Convolutions)\n",
    "\n",
    "Cel wykładu:\n",
    "- Zastosowanie konwolucji do obrazów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytywanie i wyświetlanie obrazów\n",
    "\n",
    "Kod poniżej wczytuje obrazek umieszcza go w tablicy `numpy` i wyświetla w notatniku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = imread(\"pwr.jpg\")\n",
    "sample_image= sample_image.astype(\"float32\")\n",
    "\n",
    "size = sample_image.shape\n",
    "print(\"sample image shape: \", sample_image.shape)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(sample_image.astype('uint8'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prosty filtr konwolucyjny (convolution filter)\n",
    "\n",
    "Wykorzystamy Keras'a (tensorflow) do wykonywania konwolucji na obrazku. **Nie będziemy na razie przeprowadzać uczenia w tych modelach celem jest wizualne zrozumienie działania konwolucji**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv = Conv2D(filters=3, kernel_size=(5, 5), padding=\"same\",\n",
    "              input_shape=(None, None, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uwaga**: w Kerasie, `None` jest wykorzystywany do wskazania, że wymiar tensora ma dynamiczny rozmiar.\n",
    "W tym przypadku `batch_size`, `width` i `height` są wszystkie dynamiczne: czyli po prostu zależą od wejścia (input). Tylko liczba kanałów wejściowych (input channels) jest ustalona na 3 oraz wielkość `kernel` jest (5,5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_in = np.expand_dims(sample_image, 0)\n",
    "img_in.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wynik zastosowania konwolucji do obrazka "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_out = conv(img_in)\n",
    "print(type(img_out), img_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyjściem `Conv2D` jest klasa tensorflow Eager Tensor, którą możemy przekonwerterować do standardowej\n",
    "tablicy `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_img_out = img_out[0].numpy()\n",
    "print(type(np_img_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(nrows=2, figsize=(15, 25))\n",
    "ax0.set_title('Oryginalny obrazek')\n",
    "ax1.set_title('Konwoulcja')\n",
    "ax0.imshow(sample_image.astype('uint8'))\n",
    "ax1.imshow(np_img_out.astype('uint8'));\n",
    "fig.tight_layout(pad=0.05)\n",
    "plt.subplots_adjust(bottom=0.175, wspace=0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza\n",
    "\n",
    "Wyjście ma 3 kanały, możemy to interpretować jako obrazek RGB. Zauważmy, że za każdym razem wykonując\n",
    "Conv2D (kownolucje) dostaniemy inny wynik. Domyślnie filtr (podobnie jak wagi w sieciach feedforword)\n",
    "inicjalizowany jest wartościami losowymi.\n",
    "\n",
    "Zobaczmy, więc parametry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Każdy z 3 kanałów wyjść jest generowany przez inne jądro konwolucji (convolution kernel).\n",
    "Każde jądro konwolucyjne (convolution kernel) ma wymiar 5x5 i operuje na 3 wejściach kanałów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(conv.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = conv.get_weights()[0]\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = conv.get_weights()\n",
    "#biases.shape\n",
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jedno odchylenie (bias) na kanał wyjściowy.\n",
    "\n",
    "Zamiast tego możemy zbudować jądro, definiując funkcję, która zostanie przekazana do warstwy `Conv2D`.\n",
    "Stworzymy tablicę z wartościami np. 1/45 dla filtrów, z każdym kanałem oddzielnie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_init(shape=(5, 5, 3, 3), dtype=None):\n",
    "    array = np.zeros(shape=shape, dtype=\"float32\")\n",
    "    array[:, :, 0, 0] = 1 / 45\n",
    "    array[:, :, 1, 1] = 1 / 45\n",
    "    array[:, :, 2, 2] = 1 / 45\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy wyświetlić filtry numpy, przesuwając wymiary przestrzenne na końcu (używając `np.transpose`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(my_init(), (2, 3, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv = Conv2D(filters=3, kernel_size=(5, 5), padding=\"same\",\n",
    "           input_shape=(None, None, 3), kernel_initializer=my_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(nrows=2, figsize=(15, 25))\n",
    "ax0.set_title('Oryginalny obrazek')\n",
    "ax1.set_title('Konwoulcja')\n",
    "\n",
    "ax0.imshow(img_in[0].astype('uint8'))\n",
    "\n",
    "img_out = conv(img_in)\n",
    "np_img_out = img_out[0].numpy()\n",
    "ax1.imshow(np_img_out.astype('uint8'));\n",
    "fig.tight_layout(pad=0.05)\n",
    "plt.subplots_adjust(bottom=0.175, wspace=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Zdefiniujemy warstwę Conv2D z 3 filtrami (5x5), które obliczają funkcję tożsamości (zachowajmy obraz wejściowy bez mieszania kolorów).\n",
    "- Zmienimy `strade` na 2. Zobacz jaki jest rozmiar obrazu wyjściowego (patrz na osie)\n",
    "- Zmienimy wypełnienie na „VALID”. Co obserwujesz? (patrz na print-y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_init(shape=(5, 5, 3, 3), dtype=None):\n",
    "    array = np.zeros(shape=shape, dtype=\"float32\")\n",
    "    array[2, 2] = np.eye(3)\n",
    "    return array\n",
    "\n",
    "\n",
    "conv_strides_same = Conv2D(filters=3, kernel_size=5, strides=2,\n",
    "           padding=\"same\", kernel_initializer=my_init,\n",
    "           input_shape=(None, None, 3))\n",
    "\n",
    "conv_strides_valid = Conv2D(filters=3, kernel_size=5, strides=2,\n",
    "           padding=\"valid\", kernel_initializer=my_init,\n",
    "           input_shape=(None, None, 3))\n",
    "\n",
    "img_in = np.expand_dims(sample_image, 0)\n",
    "img_out_same = conv_strides_same(img_in)[0].numpy()\n",
    "img_out_valid = conv_strides_valid(img_in)[0].numpy()\n",
    "\n",
    "print(\"Shape of original image:\", sample_image.shape)\n",
    "print(\"Shape of result with SAME padding:\", img_out_same.shape)\n",
    "print(\"Shape of result with VALID padding:\", img_out_valid.shape)\n",
    "\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(15, 36))\n",
    "ax0.imshow(img_in[0].astype(np.uint8))\n",
    "ax1.imshow(img_out_same.astype(np.uint8))\n",
    "ax2.imshow(img_out_valid.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza\n",
    "\n",
    "Obserwujemy, że `stride` dzieli rozmiar obrazu przez 2\n",
    "W przypadku trybu padding „VALID”, padding nie jest dodawany, więc\n",
    "rozmiar wyjściowego obrazu jest w rzeczywistości o 2 mniejszy z powodu\n",
    "rozmiar jądra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wykrywanie krawędzi (edge detection) na obrazkach monochromatycznych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# convert image to greyscale\n",
    "grey_sample_image = sample_image.mean(axis=2)\n",
    "\n",
    "# add the channel dimension even if it's only one channel so\n",
    "# as to be consistent with Keras expectations.\n",
    "grey_sample_image = grey_sample_image[:, :, np.newaxis]\n",
    "\n",
    "\n",
    "# matplotlib does not like the extra dim for the color channel\n",
    "# when plotting gray-level images. Let's use squeeze:\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(np.squeeze(grey_sample_image.astype(np.uint8)),\n",
    "           cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbudujemy detektor krawędzi za pomocą `Conv2D` na obrazie w skali szarości\n",
    "- Możesz eksperymentować z kilkoma jądrami, aby znaleźć sposób na wykrycie krawędzi\n",
    "- https://en.wikipedia.org/wiki/Kernel_(image_processing)\n",
    "\n",
    "Spróbuj `Conv2D?` 'Lub naciśnij` shift-tab`, aby uzyskać dokumentację. Możesz uzyskać pomoc na https://keras.io/layers/convolutional/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_init(shape, dtype=None):\n",
    "    array = np.array([\n",
    "        [0.0,  0.2, 0.0],\n",
    "        [0.0, -0.2, 0.0],\n",
    "        [0.0,  0.0, 0.0],\n",
    "    ], dtype=\"float32\")\n",
    "    # adds two axis to match the required shape (3,3,1,1)\n",
    "    return np.expand_dims(np.expand_dims(array,-1),-1)\n",
    "\n",
    "\n",
    "conv_edge = Conv2D(kernel_size=(3,3), filters=1,\n",
    "           padding=\"same\", kernel_initializer=my_init,\n",
    "           input_shape=(None, None, 1))\n",
    "\n",
    "img_in = np.expand_dims(grey_sample_image, 0)\n",
    "img_out = conv_edge(img_in).numpy()\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(15, 15))\n",
    "ax0.imshow(np.squeeze(img_in[0]).astype(np.uint8),\n",
    "           cmap=plt.cm.gray);\n",
    "ax1.imshow(np.squeeze(img_out[0]).astype(np.uint8),\n",
    "           cmap=plt.cm.gray);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza\n",
    "\n",
    "Pokazujemy tutaj tylko wykrywanie krawędzi pionowej.\n",
    "Wiele innych jąder działa, na przykład \"różnice\n",
    "wyśrodkowanych gaussów\" (centred gaussian)\n",
    "\n",
    "Możesz spróbować również z tym filtrem\n",
    "```python\n",
    "np.array ([\n",
    "         [0,1, 0,2, 0,1],\n",
    "         [0,0, 0,0, 0,0],\n",
    "         [-0,1, -0,2, -0,1],\n",
    "   ], dtype = \"float32\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling i strides z konwolucją\n",
    "\n",
    "- Użyjemy `MaxPool2D`, aby zastosować maksymalną pulę (max pool) 2x2 z krokiem (strides) 2 do obrazu. Jaki jest wpływ na kształt obrazu?\n",
    "- Użyjemy `AvgPool2D`, aby zastosować średnią pulę (average pooling).\n",
    "- Czy można obliczyć maksymalną pulę i średnią pulę przy dobrze dobranych jądrach?\n",
    "\n",
    "**Dodatek**\n",
    "- Wdrożenie puli średniej 3x3 z regularnym splotem `Conv2D`, z dobrze dobranymi krokami, jądrem i paddingiem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPool2D, AvgPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutaj dałem trochę duże wartości, aby było \"widać\" efekt pool_size=10, strides=20\n",
    "# poeksperymentuj z innymi wartościami!\n",
    "\n",
    "max_pool = MaxPool2D(pool_size=10, strides=20, input_shape=(None, None, 3))\n",
    "img_in = np.expand_dims(sample_image, 0)\n",
    "img_out = max_pool(img_in).numpy()\n",
    "\n",
    "print(\"input shape:\", img_in.shape)\n",
    "print(\"output shape:\", img_out.shape)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(15, 25))\n",
    "ax0.set_title('Oryginalny obrazek')\n",
    "ax1.set_title('MaxPool')\n",
    "ax0.imshow(img_in[0].astype('uint8'))\n",
    "ax1.imshow(img_out[0].astype('uint8'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uwaga:** Możliwe jest zbudowanie `max pool` wykorzystując standardową konwolucje `Conv2D`. Podobnie możliwe jest zbudowanie `avg pool` z odpowiednio dobranymi parametrami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pool = AvgPool2D(3, strides=3, input_shape=(None, None, 3))\n",
    "\n",
    "img_in = np.expand_dims(sample_image, 0)\n",
    "img_out_avg_pool = avg_pool(img_in).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta sama operacja zaimplementowana za pomocą konwolucji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_init(shape=(3, 3, 3, 3), dtype=None):\n",
    "    array = np.zeros(shape=shape, dtype=\"float32\")\n",
    "    array[:, :, 0, 0] = 1 / 9.\n",
    "    array[:, :, 1, 1] = 1 / 9.\n",
    "    array[:, :, 2, 2] = 1 / 9.\n",
    "    return array\n",
    "\n",
    "conv_avg = Conv2D(kernel_size=3, filters=3, strides=3,\n",
    "           padding=\"valid\", kernel_initializer=my_init,\n",
    "           input_shape=(None, None, 3))\n",
    "\n",
    "img_out_conv = conv_avg(np.expand_dims(sample_image, 0)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"input shape:\", img_in.shape)\n",
    "print(\"output avg pool shape:\", img_out_avg_pool.shape)\n",
    "print(\"output conv shape:\", img_out_conv.shape)\n",
    "\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(15, 35))\n",
    "ax0.imshow(img_in[0].astype('uint8'))\n",
    "ax1.imshow(img_out_avg_pool[0].astype('uint8'))\n",
    "ax2.imshow(img_out_conv[0].astype('uint8'));\n",
    "\n",
    "# zauważ dostajemy że \"prawie\" to samo!\n",
    "print(\"Avg pool is similar to Conv ? -\", np.allclose(img_out_avg_pool, img_out_conv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
